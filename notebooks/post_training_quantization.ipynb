{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gait.utils import compute_resultant_acceleration, split_test_train_by_subjects, compute_resultant_gyro, compute_resultant_angle, get_overlap_data_all_sessions, create_dir\n",
    "from gait.training import change_x_lstm_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_shape_lstm(X):\n",
    "    n_steps, n_length = 4, 32\n",
    "    return X.reshape((X.shape[0], n_steps, n_length, 12))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std_values(X, channel):\n",
    "    return X[:, :, channel].std(axis=1)\n",
    "\n",
    "\n",
    "def get_mean_values(X, channel):\n",
    "    return X[:, :, channel].mean(axis=1)\n",
    "\n",
    "\n",
    "def get_max_values(X, channel):\n",
    "    return X[:, :, channel].max(axis=1)\n",
    "\n",
    "\n",
    "def get_statistic_feature_all_channels(X):\n",
    "    statistic_features = []\n",
    "\n",
    "    for channel in range(9,12):\n",
    "        value = get_std_values(X, channel)\n",
    "        print('value shape', value.shape)\n",
    "        statistic_features.append(value)\n",
    "        statistic_features.append(get_mean_values(X, channel))\n",
    "        statistic_features.append(get_max_values(X, channel))\n",
    "\n",
    "    return np.vstack(statistic_features).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERLAP_PERCENT = 80\n",
    "# overlapPercents = [0]\n",
    "exclude_subjects = ['ddAeJA42PXvwthbW', 'nan', 'sUZBISq61Y7I5tqQ', 'LLZjAPTyj7muHsEf',\n",
    "                    'cbOZWnI7s1y8oLD4', 'EUbKPOSQgjccjtvi', 'MMuX9YIh4NTbLZLM',\n",
    "                    'PE8D53oX060qLbdX', 'ddAeJA42PXvwthbW', 'xYdtS1F8tDyjEIgN', '19AoxD1bgrDckd2p',\n",
    "                    'wtyNo4LYaWXrkzA7']\n",
    "\n",
    "X, y, subjects = get_overlap_data_all_sessions(OVERLAP_PERCENT)\n",
    "# REMOVE UNWANTED SUBJECTS\n",
    "indexes = np.where(subjects == exclude_subjects)\n",
    "X = np.delete(X, indexes[0], axis=0)\n",
    "y = np.delete(y, indexes[0], axis=0)\n",
    "subjects = np.delete(subjects, indexes[0], axis=0)\n",
    "# END REMOVE UNWANTED SUBJECTS\n",
    "# AUGMENT DATA\n",
    "resultant_acc = compute_resultant_acceleration(X)\n",
    "resultant_gyro = compute_resultant_gyro(X)\n",
    "resultant_angle = compute_resultant_angle(X)\n",
    "resultant_acc = resultant_acc.reshape(\n",
    "    resultant_acc.shape[0], resultant_acc.shape[1], 1)\n",
    "resultant_gyro = resultant_gyro.reshape(\n",
    "    resultant_gyro.shape[0], resultant_gyro.shape[1], 1)\n",
    "resultant_angle = resultant_angle.reshape(\n",
    "    resultant_angle.shape[0], resultant_angle.shape[1], 1)\n",
    "X = np.concatenate((X, resultant_acc), axis=2)\n",
    "X = np.concatenate((X, resultant_gyro), axis=2)\n",
    "X = np.concatenate((X, resultant_angle), axis=2)\n",
    "# AUGMENT DATA END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape (69508,)\n",
      "value shape (69508,)\n",
      "value shape (69508,)\n",
      "value shape (11024,)\n",
      "value shape (11024,)\n",
      "value shape (11024,)\n",
      "(69508, 9)\n"
     ]
    }
   ],
   "source": [
    "# trainX = change_x_lstm_shape(X)\n",
    "# print('UNIQUE subjects:', np.unique(subjects))\n",
    "X_train, X_test, y_train, y_test, y_train_non_encoded, y_test_non_encoded = split_test_train_by_subjects(\n",
    "    X, y, subjects, train_percent=0.9)\n",
    "X_train_stats = get_statistic_feature_all_channels(X_train)\n",
    "X_test_stats = get_statistic_feature_all_channels(X_test)\n",
    "print(X_train_stats.shape)\n",
    "representative_dataset = X.astype(np.float32)\n",
    "representative_stat_dataset = X_train_stats.astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 128, 12, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " quantize_layer (QuantizeLayer)  (None, 128, 12, 1)  3           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " quant_conv2d_2 (QuantizeWrappe  (None, 64, 6, 96)   14113       ['quantize_layer[0][0]']         \n",
      " rV2)                                                                                             \n",
      "                                                                                                  \n",
      " quant_batch_normalization_2 (Q  (None, 64, 6, 96)   385         ['quant_conv2d_2[0][0]']         \n",
      " uantizeWrapperV2)                                                                                \n",
      "                                                                                                  \n",
      " quant_activation_2 (QuantizeWr  (None, 64, 6, 96)   3           ['quant_batch_normalization_2[0][\n",
      " apperV2)                                                        0]']                             \n",
      "                                                                                                  \n",
      " quant_average_pooling2d_2 (Qua  (None, 32, 3, 96)   3           ['quant_activation_2[0][0]']     \n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_conv2d_3 (QuantizeWrappe  (None, 32, 3, 64)   55489       ['quant_average_pooling2d_2[0][0]\n",
      " rV2)                                                            ']                               \n",
      "                                                                                                  \n",
      " quant_batch_normalization_3 (Q  (None, 32, 3, 64)   257         ['quant_conv2d_3[0][0]']         \n",
      " uantizeWrapperV2)                                                                                \n",
      "                                                                                                  \n",
      " quant_activation_3 (QuantizeWr  (None, 32, 3, 64)   3           ['quant_batch_normalization_3[0][\n",
      " apperV2)                                                        0]']                             \n",
      "                                                                                                  \n",
      " quant_average_pooling2d_3 (Qua  (None, 16, 1, 64)   3           ['quant_activation_3[0][0]']     \n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 18)]         0           []                               \n",
      "                                                                                                  \n",
      " quant_flatten_1 (QuantizeWrapp  (None, 1024)        1           ['quant_average_pooling2d_3[0][0]\n",
      " erV2)                                                           ']                               \n",
      "                                                                                                  \n",
      " quantize_layer_1 (QuantizeLaye  (None, 18)          1           ['input_4[0][0]']                \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " quant_concatenate_1 (QuantizeW  (None, 1042)        3           ['quant_flatten_1[0][0]',        \n",
      " rapperV2)                                                        'quantize_layer_1[0][0]']       \n",
      "                                                                                                  \n",
      " quant_dense_2 (QuantizeWrapper  (None, 64)          66757       ['quant_concatenate_1[0][0]']    \n",
      " V2)                                                                                              \n",
      "                                                                                                  \n",
      " quant_dropout_1 (QuantizeWrapp  (None, 64)          1           ['quant_dense_2[0][0]']          \n",
      " erV2)                                                                                            \n",
      "                                                                                                  \n",
      " quant_dense_3 (QuantizeWrapper  (None, 6)           395         ['quant_dropout_1[0][0]']        \n",
      " V2)                                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 137,417\n",
      "Trainable params: 136,742\n",
      "Non-trainable params: 675\n",
      "__________________________________________________________________________________________________\n",
      "best_model.43-0.69-0.76.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_2_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses, activation_2_layer_call_fn, activation_2_layer_call_and_return_conditional_losses, conv2d_3_layer_call_fn while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzb0b8_yf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzb0b8_yf/assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "with tfmot.quantization.keras.quantize_scope():\n",
    "  model_path = '../models/model_80_overlap/best_model.43-0.69-0.76.hdf5'\n",
    "  loaded_model = keras.models.load_model(model_path)\n",
    "  loaded_model.summary()\n",
    "  QUANTIZED_ROOT = './quantized'\n",
    "  tflite_model_name = 'model.tflite'\n",
    "  quantized_model_name = 'model_quantized.tflite'\n",
    "  print(model_path.split('/')[3])\n",
    "  model_paths = model_path.split('/')\n",
    "  \n",
    "  tflite_path = os.path.join(QUANTIZED_ROOT, *model_paths[2:-1])\n",
    "  tflite_filepath = os.path.join(\n",
    "      QUANTIZED_ROOT, *model_paths[2:-1], tflite_model_name)\n",
    "  create_dir(tflite_path)\n",
    "  \n",
    "  converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
    "  converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "  ]\n",
    "  tflite_model = converter.convert()\n",
    "  open(tflite_filepath, 'wb').write(tflite_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69508, 128, 12)\n",
      "(69508, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train_stats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, X_train.shape[1], X_train.shape[2], 1).astype(np.float32)\n",
    "representative_dataset = X_train.astype(np.float32)\n",
    "representative_stat_dataset = X_train_stats.astype(np.float32)\n",
    "\n",
    "\n",
    "# def representative_dataset_gen():\n",
    "#     for data in tf.data.Dataset.from_tensor_slices((representative_dataset)).batch(1).take(100):\n",
    "#         for stat_data in tf.data.Dataset.from_tensor_slices((representative_stat_dataset)).batch(1).take(100):\n",
    "#             yield [tf.dtypes.cast(data, tf.float32), tf.dtypes.cast(stat_data, tf.float32)]\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    for _ in range(100):\n",
    "        data1, data2 = np.random.rand(1, 128, 12, 1), np.random.rand(1, 12)\n",
    "        yield [data1.astype(np.float32), data2.astype(np.float32)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, activation_layer_call_fn, activation_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpsajni_za/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpsajni_za/assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, activation_layer_call_fn, activation_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp77t87ggf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp77t87ggf/assets\n",
      "/home/sanjeev/.local/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "with tfmot.quantization.keras.quantize_scope():\n",
    "  quantized_model_name = 'model_quantized.tflite'\n",
    "  model_path = '../best_model/cnn_stat/80_overlap/best_model.100-0.59-0.78.hdf5'\n",
    "  loaded_model = keras.models.load_model(model_path)\n",
    "  converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
    "  converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "  ]\n",
    "  tflite_model = converter.convert()\n",
    "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "  converter.representative_dataset = representative_dataset_gen\n",
    "  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "  converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "  converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "  tflite_quantized_model = converter.convert()\n",
    "  \n",
    "  tflite_quantized_model_filtepath =  os.path.join(\n",
    "      QUANTIZED_ROOT, *model_paths[2:-1], quantized_model_name)\n",
    "  \n",
    "  open(tflite_quantized_model_filtepath, \"wb\").write(tflite_model)\n",
    "\n",
    "  \n",
    "  # print(\"Basic model is %d bytes\" % basic_model_size)\n",
    "  # quantized_model_size = os.path.getsize(tflite_quantized_model)\n",
    "  # print(\"Quantized model is %d bytes\" % quantized_model_size)\n",
    "  # difference = basic_model_size - quantized_model_size\n",
    "  # print(\"Difference is %d bytes\" % difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./quantized/cnn_stat/80_overlap/model_quantized.tflite\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "tflite_quantized_model_filtepath\n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb44b4e6cc691712e826bba4e724ba947229be6916e0acb92c0db1c9ddbd3c7a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
